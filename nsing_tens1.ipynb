{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nsing_tens1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxwV94U-CsR0"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import time\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.engine.topology import Layer\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_wgqvhfQLFM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1zidU_PQUps"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/Dataset/Mini\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqD2mA057Is"
      },
      "source": [
        "path = \"/content/drive/My Drive/Dataset/Mini/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFV0-IxBHvs3"
      },
      "source": [
        "dir_list = next(os.walk(path))[1]\n",
        "dir_list.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ngci15v6wzE"
      },
      "source": [
        "\n",
        "  orig_groups, forg_groups = [],[]\n",
        "for i in dir_list:\n",
        "  images=os.listdir(path+i)\n",
        "  images.sort()\n",
        "  images=[path+i+'/'+x for x in images]\n",
        "  forg_groups.append(images[:10])\n",
        "  orig_groups.append(images[10:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myZCsVhe0bh_"
      },
      "source": [
        "dir_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-caTkVMzwO6"
      },
      "source": [
        "len(orig_groups),len(forg_groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G-WTqFJ1UbF"
      },
      "source": [
        "orig_lengths=[len(x) for x in orig_groups]\n",
        "forg_lengths=[len(x) for x in forg_groups]\n",
        "print(orig_lengths)\n",
        "print(forg_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZk8Mc7N1yyk"
      },
      "source": [
        "orig_train, orig_val, orig_test=orig_groups[:6],orig_groups[6:8],orig_groups[8:]\n",
        "forg_train, forg_val, forg_test=forg_groups[:6],forg_groups[6:8],forg_groups[8:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k393wX5cbZmt"
      },
      "source": [
        "forg_train, forg_val, forg_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRLNYRvp6QiC"
      },
      "source": [
        "img_h, img_w=155,220"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5POus0qn6Y2S"
      },
      "source": [
        "def visualize_sample_face():\n",
        "  fig, (ax1, ax2, ax3)=plt.subplots(1,3,figsize=(10,10))\n",
        "  k=np.random.randint(len(orig_train))\n",
        "  orig_img_names=random.sample(orig_train[k],2)\n",
        "  forg_img_name=random.sample(forg_train[k],1)\n",
        "  orig_img1=cv2.imread(orig_img_names[0],0)\n",
        "  orig_img2=cv2.imread(orig_img_names[1],0)\n",
        "  forg_img=plt.imread(forg_img_name[0],0)\n",
        "  orig_img1=cv2.resize(orig_img1,(img_w,img_h))\n",
        "  orig_img2=cv2.resize(orig_img2,(img_w,img_h))\n",
        "  forg_img1=cv2.resize(forg_img,(img_w,img_h))\n",
        "\n",
        "  ax1.imshow(orig_img1, cmap='gray')\n",
        "  ax2.imshow(orig_img2, cmap='gray')\n",
        "  ax3.imshow(forg_img1, cmap='gray')\n",
        "\n",
        "  ax1.set_title('Similar face')\n",
        "  ax1.axis('off')\n",
        "  ax2.set_title('Similar face')\n",
        "  ax2.axis('off')\n",
        "  ax3.set_title('Dissimilar face')\n",
        "  ax3.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKRXHxdQ9CNF"
      },
      "source": [
        "visualize_sample_face()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBjkNOvb8oay"
      },
      "source": [
        "def generate_batch(orig_groups, forg_groups, batch_size = 2):\n",
        "    '''Function to generate a batch of data with batch_size number of data points\n",
        "    Half of the data points will be Genuine-Genuine pairs and half will be Genuine-Forged pairs'''\n",
        "    while True:\n",
        "        orig_pairs = []\n",
        "        forg_pairs = []\n",
        "        gen_gen_labels = []\n",
        "        gen_for_labels = []\n",
        "        all_pairs = []\n",
        "        all_labels = []\n",
        "        \n",
        "        # Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
        "        # For every person we have 24 genuine signatures, hence we have \n",
        "        # 24 choose 2 = 276 Genuine-Genuine image pairs for one person.\n",
        "        # To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
        "        # with 12 randomly sampled Forged signatures of the same person.\n",
        "        # Thus we make 24 * 12 = 300 Genuine-Forged image pairs for one person.\n",
        "        # In all we have 120 person's data in the training data.\n",
        "        # Total no. of Genuine-Genuine pairs = 120 * 276 = 33120\n",
        "        # Total number of Genuine-Forged pairs = 120 * 300 = 36000\n",
        "        # Total no. of data points = 33120 + 36000 = 69120\n",
        "        for orig, forg in zip(orig_groups, forg_groups):\n",
        "            orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
        "            for i in range(len(forg)):\n",
        "                forg_pairs.extend(list(itertools.product(orig[i:i+1], random.sample(forg, 12))))\n",
        "        \n",
        "        # Label for Genuine-Genuine pairs is 1\n",
        "        # Label for Genuine-Forged pairs is 0\n",
        "        gen_gen_labels = [1]*len(orig_pairs)\n",
        "        gen_for_labels = [0]*len(forg_pairs)\n",
        "        \n",
        "        # Concatenate all the pairs together along with their labels and shuffle them\n",
        "        all_pairs = orig_pairs + forg_pairs\n",
        "        all_labels = gen_gen_labels + gen_for_labels\n",
        "        del orig_pairs, forg_pairs, gen_gen_labels, gen_for_labels\n",
        "        all_pairs, all_labels = shuffle(all_pairs, all_labels)\n",
        "        \n",
        "        # Note the lists above contain only the image names and\n",
        "        # actual images are loaded and yielded below in batches\n",
        "        # Below we prepare a batch of data points and yield the batch\n",
        "        # In each batch we load \"batch_size\" number of image pairs\n",
        "        # These images are then removed from the original set so that\n",
        "        # they are not added again in the next batch.\n",
        "            \n",
        "        k = 0\n",
        "        pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "        targets=np.zeros((batch_size,))\n",
        "        for ix, pair in enumerate(all_pairs):\n",
        "            img1 = cv2.imread(pair[0], 0)\n",
        "            img2 = cv2.imread(pair[1], 0)\n",
        "            img1 = cv2.resize(img1, (img_w, img_h))\n",
        "            img2 = cv2.resize(img2, (img_w, img_h))\n",
        "            img1 = np.array(img1, dtype = np.float64)\n",
        "            img2 = np.array(img2, dtype = np.float64)\n",
        "            img1 /= 255\n",
        "            img2 /= 255\n",
        "            img1 = img1[..., np.newaxis]\n",
        "            img2 = img2[..., np.newaxis]\n",
        "            pairs[0][k, :, :, :] = img1\n",
        "            pairs[1][k, :, :, :] = img2\n",
        "            targets[k] = all_labels[ix]\n",
        "            k += 1\n",
        "            if k == batch_size:\n",
        "                yield pairs, targets\n",
        "                k = 0\n",
        "                pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "                targets=np.zeros((batch_size,))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-21W2TQZeEU"
      },
      "source": [
        "def euclidean_distance(vects):\n",
        "    '''Compute Euclidean Distance between two vectors'''\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bCPu91FZjaA"
      },
      "source": [
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z5NITpXZqYD"
      },
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    '''Contrastive loss from Hadsell-et-al.'06\n",
        "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    '''\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIsoaXy-Zxtv"
      },
      "source": [
        "def create_base_network_signet(input_shape):\n",
        "    '''Base Siamese Network'''\n",
        "    \n",
        "    seq = Sequential()\n",
        "    seq.add(Conv2D(96, kernel_size=(11, 11), activation='relu', name='conv1_1', strides=4, input_shape= input_shape, \n",
        "                        init='glorot_uniform', dim_ordering='tf'))\n",
        "    seq.add(BatchNormalization(epsilon=1e-06, mode=0, axis=1, momentum=0.9))\n",
        "    seq.add(MaxPooling2D((3,3), strides=(2, 2)))    \n",
        "    seq.add(ZeroPadding2D((2, 2), dim_ordering='tf'))\n",
        "    \n",
        "    seq.add(Conv2D(256, kernel_size=(5, 5), activation='relu', name='conv2_1', strides=1, init='glorot_uniform',  dim_ordering='tf'))\n",
        "    seq.add(BatchNormalization(epsilon=1e-06, mode=0, axis=1, momentum=0.9))\n",
        "    seq.add(MaxPooling2D((3,3), strides=(2, 2)))\n",
        "    seq.add(Dropout(0.3))# added extra\n",
        "    seq.add(ZeroPadding2D((1, 1), dim_ordering='tf'))\n",
        "    \n",
        "    seq.add(Conv2D(384, kernel_size=(3, 3), activation='relu', name='conv3_1', strides=1, init='glorot_uniform',  dim_ordering='tf'))\n",
        "    seq.add(ZeroPadding2D((1, 1), dim_ordering='tf'))\n",
        "    \n",
        "    seq.add(Conv2D(256, kernel_size=(3, 3), activation='relu', name='conv3_2', strides=1, init='glorot_uniform', dim_ordering='tf'))    \n",
        "    seq.add(MaxPooling2D((3,3), strides=(2, 2)))\n",
        "    seq.add(Dropout(0.3))# added extra\n",
        "    seq.add(Flatten(name='flatten'))\n",
        "    seq.add(Dense(1024, W_regularizer=l2(0.0005), activation='relu', init='glorot_uniform'))\n",
        "    seq.add(Dropout(0.5))\n",
        "    \n",
        "    seq.add(Dense(128, W_regularizer=l2(0.0005), activation='relu', init='glorot_uniform')) # softmax changed to relu\n",
        "    \n",
        "    return seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwQTV6kZZ4Vd"
      },
      "source": [
        "input_shape=(img_h, img_w, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cia9fBhZ782"
      },
      "source": [
        "#network definition\n",
        "base_network = create_base_network_signet(input_shape)\n",
        "\n",
        "input_a = Input(shape=(input_shape))\n",
        "input_b = Input(shape=(input_shape))\n",
        "\n",
        "# because we re-use the same instance `base_network`,\n",
        "# the weights of the network\n",
        "# will be shared across the two branches\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "# Compute the Euclidean distance between the two vectors in the latent space\n",
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "\n",
        "model = Model(input=[input_a, input_b], output=distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX4p8kgVaJz8"
      },
      "source": [
        "batch_sz = 5\n",
        "num_train_samples = 10*6 +10*6\n",
        "num_val_samples = num_test_samples = 10*2 +10*2\n",
        "num_train_samples, num_val_samples, num_test_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYMxxk0FctTn"
      },
      "source": [
        "# compile model using RMSProp Optimizer and Contrastive loss function defined above\n",
        "rms = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08)\n",
        "model.compile(loss=contrastive_loss, optimizer=rms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdJ795X3aXYE"
      },
      "source": [
        "callbacks1 = ModelCheckpoint(filepath='./Weights/signet-mini-{epoch:03d}.h5', verbose=1, save_weights_only=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbf0MkTafZa"
      },
      "source": [
        "results = model.fit_generator(generate_batch(orig_train, forg_train, batch_sz),\n",
        "                              steps_per_epoch = 2,\n",
        "                              epochs = 2,\n",
        "                              callbacks = [callbacks1],\n",
        "                              validation_data = generate_batch(orig_val, forg_val, batch_sz),\n",
        "                              validation_steps = 10,\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nhG-yLsat_a"
      },
      "source": [
        "model.load_weights('./Weights/signet-mini-009.h5')\n",
        "test_gen = generate_batch(orig_test, forg_test, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnEk2ngcB0C-"
      },
      "source": [
        "pred, tr_y = [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fARdXCmRa1f_"
      },
      "source": [
        "\n",
        "for i in range(num_test_samples):\n",
        "    (img1, img2), label = next(test_gen)\n",
        "    tr_y.append(label)\n",
        "    pred.append(model.predict([img1, img2])[0][0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEdslXpFa7dV"
      },
      "source": [
        "tr_acc, threshold = compute_accuracy_roc(np.array(pred), np.array(tr_y))\n",
        "tr_acc, threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67VY7Q38bAx0"
      },
      "source": [
        "def predict_score():\n",
        "    '''Predict distance score and classify test images as Genuine or Forged'''\n",
        "    test_point, test_label = next(test_gen)\n",
        "    img1, img2 = test_point[0], test_point[1]\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 10))\n",
        "    ax1.imshow(np.squeeze(img1), cmap='gray')\n",
        "    ax2.imshow(np.squeeze(img2), cmap='gray')\n",
        "    ax1.set_title('Genuine')\n",
        "    if test_label == 1:\n",
        "        ax2.set_title('Similar')\n",
        "    else:\n",
        "        ax2.set_title('Dissimilar')\n",
        "    ax1.axis('off')\n",
        "    ax2.axis('off')\n",
        "    plt.show()\n",
        "    result = model.predict([img1, img2])\n",
        "    diff = result[0][0]\n",
        "    print(\"Difference Score = \", diff)\n",
        "    if diff > threshold:\n",
        "        print(\"It is Similar person\")\n",
        "    else:\n",
        "        print(\"It is Dissimilar person\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkUjilqubEsO"
      },
      "source": [
        "predict_score()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySBIHITBan_I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}